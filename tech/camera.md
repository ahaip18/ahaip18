## [啊哈，莱卡！](https://ahaleica.com/)

![image](https://user-images.githubusercontent.com/109412346/179347719-ceb4a4b1-ddcf-44be-ad33-fe2373c16242.png)
![image](https://user-images.githubusercontent.com/109412346/179347742-ab6b444a-9c07-46b8-af60-6926bdc4688d.png)
![image](https://user-images.githubusercontent.com/109412346/179347734-290c9f53-f18e-43e4-b264-4713be83d380.png)
![image](https://user-images.githubusercontent.com/109412346/179347727-7f8d9075-5488-42b8-b304-a0e2a81866db.png)
![image](https://user-images.githubusercontent.com/109412346/179347750-7a9046df-a79e-4496-b982-1127d9ba0762.png)

> ahaip: 发现美，记录美及创造美...

![image](https://user-images.githubusercontent.com/109412346/179381998-ee0bf868-a173-45aa-acf0-1a6b4c48844a.png)
![image](https://user-images.githubusercontent.com/109412346/179381999-3266cef0-be65-410c-9e7a-47902601c90c.png)
![image](https://user-images.githubusercontent.com/109412346/179382072-8b4ad1ae-c37b-433b-9947-559c9c3a1165.png)
![image](https://user-images.githubusercontent.com/109412346/179382074-0fa8d7a5-5921-4af6-98ec-7723a818eca8.png)

```
影像，是这个时代人们最重要的语言。
想拍就拍，想照就照。
10年后再好的相机，也拍不出这般模样。
大胆地记录生活，你现在的每天都值得珍藏。
```

![image](https://user-images.githubusercontent.com/109412346/179381885-59ea1143-9290-473d-9dc0-faef8d9215fa.png)
![image](https://user-images.githubusercontent.com/109412346/179381891-6898dfef-d172-4388-9a0d-6cbd83a3c0ed.png)
![image](https://user-images.githubusercontent.com/109412346/179381899-cd18b064-d1b6-45f3-b7fd-9fc8d090004e.png)
![image](https://user-images.githubusercontent.com/109412346/179381890-b25d763e-1371-404d-b2a2-786a49059b4a.png)
![image](https://user-images.githubusercontent.com/109412346/179381887-57d4fb9e-5f31-4e9f-9bad-2f06819b703c.png)
![image](https://user-images.githubusercontent.com/109412346/179381903-b2bfdfe9-f4a0-491b-9328-4378327291e5.png)
![image](https://user-images.githubusercontent.com/109412346/179381908-214746d9-5e6d-4c1d-b3ba-74259dc1e360.png)
![image](https://user-images.githubusercontent.com/109412346/179381911-c7dfc781-328b-4b55-8be9-3a691a99e449.png)
![image](https://user-images.githubusercontent.com/109412346/179381913-7cf44942-ef99-4f40-b4ab-a201915a313d.png)
![image](https://user-images.githubusercontent.com/109412346/179381914-5d417a77-ce4e-421d-b3d6-5d0c8fd2814b.png)
![image](https://user-images.githubusercontent.com/109412346/179381920-7e379d9f-0a3b-4e0a-9215-aa5c2c149bd4.png)
![image](https://user-images.githubusercontent.com/109412346/179381900-988b5cdc-d3ff-4549-8894-593fdd55e800.png)
![image](https://user-images.githubusercontent.com/109412346/179381904-93c2071b-1a0e-431c-98e2-d586f0d18a19.png)
![image](https://user-images.githubusercontent.com/109412346/179381910-c30e5af7-dd1b-418e-a519-9ef9b0e2bfb9.png)
![image](https://user-images.githubusercontent.com/109412346/179381921-8c56fd88-9701-48ab-980d-f2fca6f5d52f.png)
![image](https://user-images.githubusercontent.com/109412346/179381925-159767af-c55c-424b-85d6-b32e454caedf.png)
![image](https://user-images.githubusercontent.com/109412346/179381922-c7b235fb-d7fd-4507-86ef-7e091cd0423c.png)
![image](https://user-images.githubusercontent.com/109412346/179381929-ce7823db-a08e-4da5-970f-ab9877c3994b.png)
![image](https://user-images.githubusercontent.com/109412346/179381932-638743dd-74d2-4ac4-a19f-afba829c67b8.png)
![image](https://user-images.githubusercontent.com/109412346/179381924-b79482ad-8abc-4cdf-9a39-31aa8c2300b7.png)
![image](https://user-images.githubusercontent.com/109412346/179381927-b680486d-d4ef-4406-879e-42e54c768ad4.png)
![image](https://user-images.githubusercontent.com/109412346/179381897-31ec67c2-a24c-4387-8e33-18b2aa0becd9.png)
![image](https://user-images.githubusercontent.com/109412346/179381937-5fd32f03-472e-400c-95bd-67fbbcee6d8c.png)
![image](https://user-images.githubusercontent.com/109412346/179381940-5cf61fb6-3e43-4c36-ba68-3b268cee40b1.png)
![image](https://user-images.githubusercontent.com/109412346/179381935-22061483-e6ab-4185-a0c0-8495a7e9f8ae.png)
![image](https://user-images.githubusercontent.com/109412346/179381884-cfcc3bcd-841e-42f5-8831-fd54b78ca8a8.png)

![image](https://user-images.githubusercontent.com/109412346/179390071-afa31745-e0dc-4e91-90ba-737b3c38b4bd.png)
![image](https://user-images.githubusercontent.com/109412346/179390074-d508f973-5188-4d26-bb60-aa85cc46221c.png)
![image](https://user-images.githubusercontent.com/109412346/179390077-b14304c0-6849-4682-b648-f49f94d7f275.png)
![image](https://user-images.githubusercontent.com/109412346/179390080-d0ddb851-823b-4bd7-b006-41908aef478f.png)
![image](https://user-images.githubusercontent.com/109412346/179390081-fb474f6f-b71f-4655-9c82-4a8843757d5a.png)
![image](https://user-images.githubusercontent.com/109412346/179390083-caf0ba5e-eb4d-435c-ae87-2eb39382f522.png)
![image](https://user-images.githubusercontent.com/109412346/179390085-ea5c891c-a5ce-4fb1-8ca6-e8b107a6e061.png)
![image](https://user-images.githubusercontent.com/109412346/179390088-b12a735c-a456-447d-803e-2553943fa8cd.png)
![image](https://user-images.githubusercontent.com/109412346/179390094-22e22f1a-7cc9-4492-a9c9-e0a60c58025a.png)
![image](https://user-images.githubusercontent.com/109412346/179390099-7bcf4fa4-3532-44d2-ad2e-07e5dbdaf579.png)
![image](https://user-images.githubusercontent.com/109412346/179390104-bc09cf08-6c42-4e49-934d-478c40ae92c4.png)
![image](https://user-images.githubusercontent.com/109412346/179390109-2835c066-4d07-4ba2-874f-12e1faa170b6.png)
![image](https://user-images.githubusercontent.com/109412346/179390111-0f765390-69ac-481d-8baa-4cc48e4e5055.png)
![image](https://user-images.githubusercontent.com/109412346/179390115-e7395936-786d-47e5-a456-6ec63a59fc1d.png)
![image](https://user-images.githubusercontent.com/109412346/179390116-eba35d55-9295-4e9e-8c59-a668928e0c85.png)
![image](https://user-images.githubusercontent.com/109412346/179390117-bce60cac-643d-449e-8fe4-cd3845b931c7.png)
![image](https://user-images.githubusercontent.com/109412346/179390120-fd63de3e-6648-4a91-972f-91b5c4d01482.png)
![image](https://user-images.githubusercontent.com/109412346/179390123-2126a809-b07e-40bb-b33a-b6cf096ecf5f.png)
![image](https://user-images.githubusercontent.com/109412346/179390126-5468cd7a-8499-4d10-9faa-4bcc7839faaa.png)
![image](https://user-images.githubusercontent.com/109412346/179390128-645a1b71-e99d-443c-bc70-a288dc173e0b.png)
![image](https://user-images.githubusercontent.com/109412346/179390133-56805844-d68f-4c4a-95dc-3e06cc5caf9e.png)
![image](https://user-images.githubusercontent.com/109412346/179390134-98cb8697-8953-459c-99b6-420602fe0809.png)
![image](https://user-images.githubusercontent.com/109412346/179390135-8dffba03-27b3-4667-b069-ac790d7dca16.png)
![image](https://user-images.githubusercontent.com/109412346/179390137-f1c4d3b7-ad5e-4099-8864-d2c58f135dd1.png)

> ahaip: 用脚步丈量世界，用眼睛欣赏世界，用行动改善世界...纪录是第一步...

![image](https://user-images.githubusercontent.com/109412346/182011219-16a00b92-c763-442f-8231-bd852adddec3.png)
![image](https://user-images.githubusercontent.com/109412346/182011223-4369c927-30c6-4384-978a-98bbbad63f0c.png)
![image](https://user-images.githubusercontent.com/109412346/182011224-7be56c51-85a0-4042-b44e-eaff6459c22c.png)
![image](https://user-images.githubusercontent.com/109412346/182011227-e83836bd-531f-4573-b9cb-497ae0b622f6.png)
![image](https://user-images.githubusercontent.com/109412346/182011228-5e228f4d-a86e-42d2-847d-0b97051b940f.png)
![image](https://user-images.githubusercontent.com/109412346/182011230-2d05047d-72b5-40a9-b8cc-2e8ef4591304.png)
![image](https://user-images.githubusercontent.com/109412346/182011233-ff41faab-4f22-4d0b-a2e8-36dc6f5c2d5c.png)
![image](https://user-images.githubusercontent.com/109412346/182011234-8782d6e8-b0e6-4756-b3d1-d30f40e84531.png)
![image](https://user-images.githubusercontent.com/109412346/182011236-3837de9b-793e-4473-8468-84bd4be1b3e6.png)
![image](https://user-images.githubusercontent.com/109412346/182011238-a280a3df-3eaf-4ebc-833c-f38ae030305a.png)
![image](https://user-images.githubusercontent.com/109412346/182011241-0ababedb-6cad-4b06-b69f-d01cdb296abf.png)
![image](https://user-images.githubusercontent.com/109412346/182011243-6673e725-d554-4bcf-bdca-3ebb7e56e074.png)
![image](https://user-images.githubusercontent.com/109412346/182011244-d9196341-534c-48fd-9ff9-5ef3d8a7e1e2.png)
![image](https://user-images.githubusercontent.com/109412346/182011247-281a6b30-a435-4a21-bd45-5a1e6c220b71.png)
![image](https://user-images.githubusercontent.com/109412346/182011248-e9b142d3-d55f-45af-8799-ba65d4421be4.png)
![image](https://user-images.githubusercontent.com/109412346/182011251-8ea2127b-8d86-46be-bb52-18932f754139.png)
![image](https://user-images.githubusercontent.com/109412346/182011253-ca57a248-2828-40c9-9877-dabafa4cb574.png)
![image](https://user-images.githubusercontent.com/109412346/182011254-9f08f811-c971-4509-b73b-3b82698b37f1.png)
![image](https://user-images.githubusercontent.com/109412346/182011255-81b66d2e-eb5a-4732-808d-6594732332c8.png)
![image](https://user-images.githubusercontent.com/109412346/182011256-5e500cac-0345-4a1e-b713-925f3378c8e7.png)
![image](https://user-images.githubusercontent.com/109412346/182011257-ec48556d-8931-41c3-bb7e-4b7063abeec5.png)
![image](https://user-images.githubusercontent.com/109412346/182011258-c9d2ca54-0ead-4c10-b471-22654434507f.png)
![image](https://user-images.githubusercontent.com/109412346/182011259-57bd7c7f-605e-43ff-b732-7d5790e96c80.png)
![image](https://user-images.githubusercontent.com/109412346/182011261-fb4bdcdd-0e25-4c2b-9c07-e2818855d50b.png)
![image](https://user-images.githubusercontent.com/109412346/182011263-eb7279b8-6ecb-4557-b511-44bc3b99927e.png)
![image](https://user-images.githubusercontent.com/109412346/182011267-545d3994-0fdd-41ba-918c-b43358599128.png)
![image](https://user-images.githubusercontent.com/109412346/182011269-ce9b34fb-9dd5-423d-a27c-2e5786051466.png)

![image](https://user-images.githubusercontent.com/101693157/158524594-40e4376b-af71-4235-a7b1-ea72ddd9c576.png)
> 矩阵计算

## 技术原理

### [SVG 图像入门教程](https://www.ruanyifeng.com/blog/2018/08/svg.html) 

![image](https://user-images.githubusercontent.com/101693157/158824737-6329411e-3c30-4edc-99fe-7e06f084e6c0.png)

SVG 是一种基于 XML 语法的图像格式，全称是可缩放矢量图（Scalable Vector Graphics）。`其他图像格式都是基于像素处理的，SVG 则是属于对图像的形状描述，所以它本质上是文本文件，体积较小，且不管放大多少倍都不会失真。`

SVG 文件可以直接插入网页，成为 DOM 的一部分，然后用 JavaScript 和 CSS 进行操作。

SVG 代码也可以写在一个独立文件中，然后用<img>、<object>、<embed>、<iframe>等标签插入网页。

### [相似图片搜索的原理](https://www.ruanyifeng.com/blog/2011/07/principle_of_similar_image_search.html) 

2011年6月，Google把"相似图片搜索"正式放上了首页。
你可以用一张图片，搜索互联网上所有与它相似的图片。点击搜索框中照相机的图标。

![image](https://user-images.githubusercontent.com/101693157/158818343-234ae8e7-113b-46e3-9c4f-88434fdff1d5.png)

一个对话框会出现。

你输入网片的网址，或者直接上传图片，Google就会找出与其相似的图片。下面这张图片是美国女演员Alyson Hannigan。
上传后，Google返回如下结果：
类似的"相似图片搜索引擎"还有不少，TinEye甚至可以找出照片的拍摄背景。

这种技术的原理是什么？计算机怎么知道两张图片相似呢？

根据[Neal Krawetz](https://www.hackerfactor.com/blog/index.php?/archives/432-Looks-Like-It.html)博士的解释，原理非常简单易懂。我们可以用一个快速算法，就达到基本的效果。

> 这里的关键技术叫做"感知哈希算法"（Perceptual hash algorithm），它的作用是对每张图片生成一个"指纹"（fingerprint）字符串，然后比较不同图片的指纹。结果越接近，就说明图片越相似。

下面是一个最简单的实现：

第一步，缩小尺寸。
将图片缩小到8x8的尺寸，总共64个像素。这一步的作用是去除图片的细节，只保留结构、明暗等基本信息，摒弃不同尺寸、比例带来的图片差异。
第二步，简化色彩。
将缩小后的图片，转为64级灰度。也就是说，所有像素点总共只有64种颜色。
第三步，计算平均值。
计算所有64个像素的灰度平均值。
第四步，比较像素的灰度。
将每个像素的灰度，与平均值进行比较。大于或等于平均值，记为1；小于平均值，记为0。
第五步，计算哈希值。
将上一步的比较结果，组合在一起，就构成了一个64位的整数，这就是这张图片的指纹。组合的次序并不重要，只要保证所有图片都采用同样次序就行了。

得到指纹以后，就可以对比不同的图片，看看64位中有多少位是不一样的。在理论上，这等同于计算"汉明距离"（Hamming distance）。如果不相同的数据位不超过5，就说明两张图片很相似；如果大于10，就说明这是两张不同的图片。
具体的代码实现，可以参见Wote用python语言写的imgHash.py。代码很短，只有53行。使用的时候，第一个参数是基准图片，第二个参数是用来比较的其他图片所在的目录，返回结果是两张图片之间不相同的数据位数量（汉明距离）。

这种算法的优点是简单快速，不受图片大小缩放的影响，缺点是图片的内容不能变更。如果在图片上加几个文字，它就认不出来了。所以，它的最佳用途是根据缩略图，找出原图。

实际应用中，往往采用更强大的pHash算法和SIFT算法，它们能够识别图片的变形。只要变形程度不超过25%，它们就能匹配原图。这些算法虽然更复杂，但是原理与上面的简便算法是一样的，就是先将图片转化成Hash字符串，然后再进行比较。

[相似图片搜索的原理（二）](https://www.ruanyifeng.com/blog/2013/03/similar_image_search_part_ii.html)

一、颜色分布法

每张图片都可以生成颜色分布的直方图（color histogram）。如果两张图片的直方图很接近，就可以认为它们很相似。

![image](https://user-images.githubusercontent.com/101693157/158818957-b0cdf2ef-678d-4164-93c2-6bdfb734a984.png)

任何一种颜色都是由红绿蓝三原色（RGB）构成的，所以上图共有4张直方图（三原色直方图 + 最后合成的直方图）。
如果每种原色都可以取256个值，那么整个颜色空间共有1600万种颜色（256的三次方）。针对这1600万种颜色比较直方图，计算量实在太大了，因此需要采用简化方法。可以将0～255分成四个区：0～63为第0区，64～127为第1区，128～191为第2区，192～255为第3区。这意味着红绿蓝分别有4个区，总共可以构成64种组合（4的3次方）。
任何一种颜色必然属于这64种组合中的一种，这样就可以统计每一种组合包含的像素数量。

![image](https://user-images.githubusercontent.com/101693157/158819069-d098c98d-92cb-40fe-9f5b-0fbce4a0001f.png)

上图是某张图片的颜色分布表，将表中最后一栏提取出来，组成一个64维向量(7414, 230, 0, 0, 8, ..., 109, 0, 0, 3415, 53929)。`这个向量就是这张图片的特征值或者叫"指纹"。`
于是，寻找相似图片就变成了找出与其最相似的向量。这可以用皮尔逊相关系数或者余弦相似度算出。

二、内容特征法

除了颜色构成，还可以从比较图片内容的相似性入手。

首先，将原图转成一张较小的灰度图片，假定为50x50像素。然后，确定一个阈值，将灰度图片转成黑白图片。

![image](https://user-images.githubusercontent.com/101693157/158819336-877bb776-3fec-4ebd-b01b-20e7619ac3d5.png)

如果两张图片很相似，它们的黑白轮廓应该是相近的。于是，问题就变成了，第一步如何确定一个合理的阈值，正确呈现照片中的轮廓？
显然，前景色与背景色反差越大，轮廓就越明显。这意味着，如果我们找到一个值，可以使得前景色和背景色各自的"类内差异最小"（minimizing the intra-class variance），或者"类间差异最大"（maximizing the inter-class variance），那么这个值就是理想的阈值。
1979年，日本学者大津展之证明了，"类内差异最小"与"类间差异最大"是同一件事，即对应同一个阈值。他提出一种简单的算法，可以求出这个阈值，这被称为"大津法"（Otsu's method）。下面就是他的计算方法。
假定一张图片共有n个像素，其中灰度值小于阈值的像素为 n1 个，大于等于阈值的像素为 n2 个（ n1 + n2 = n ）。w1 和 w2 表示这两种像素各自的比重。
　　w1 = n1 / n
　　w2 = n2 / n
再假定，所有灰度值小于阈值的像素的平均值和方差分别为 μ1 和 σ1，所有灰度值大于等于阈值的像素的平均值和方差分别为 μ2 和 σ2。于是，可以得到
　　类内差异 = w1(σ1的平方) + w2(σ2的平方)
　　类间差异 = w1w2(μ1-μ2)^2
可以证明，这两个式子是等价的：得到"类内差异"的最小值，等同于得到"类间差异"的最大值。不过，从计算难度看，后者的计算要容易一些。

![image](https://user-images.githubusercontent.com/101693157/158819356-8679505c-c7aa-4731-8ca5-4771f422f439.png)

有了50x50像素的黑白缩略图，就等于有了一个50x50的0-1矩阵。矩阵的每个值对应原图的一个像素，0表示黑色，1表示白色。这个矩阵就是一张图片的特征矩阵。

两个特征矩阵的不同之处越少，就代表两张图片越相似。这可以用"异或运算"实现（即两个值之中只有一个为1，则运算结果为1，否则运算结果为0）。对不同图片的特征矩阵进行"异或运算"，结果中的1越少，就是越相似的图片。
  
### [如何识别图像边缘？](https://www.ruanyifeng.com/blog/2016/07/edge-recognition.html)

图像识别（image recognition）是现在的热门技术。
文字识别、车牌识别、人脸识别都是它的应用。但是，这些都算初级应用，现在的技术已经发展到了这样一种地步：计算机可以识别出，这是一张狗的照片，那是一张猫的照片。

这是怎么做到的？

让我们从人眼说起，学者发现，人的视觉细胞对物体的边缘特别敏感。也就是说，我们先看到物体的轮廓，然后才判断这到底是什么东西。
  
计算机科学家受到启发，第一步也是先识别图像的边缘。

![](https://www.ruanyifeng.com/blogimg/asset/2016/bg2016072208.png)
  
加州大学的学生 Adit Deshpande 写了一篇文章[《A Beginner's Guide To Understanding Convolutional Neural Networks》](https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/)，介绍了一种最简单的算法，非常具有启发性，体现了图像识别的基本思路。

![](https://www.ruanyifeng.com/blogimg/asset/2016/bg2016072203.png)
  
首先，我们要明白，`人看到的是图像，计算机看到的是一个数字矩阵。所谓"图像识别"，就是从一大堆数字中找出规律。`
  
怎样将图像转为数字呢？一般来说，为了过滤掉干扰信息，可以把图像缩小（比如缩小到 49 x 49 像素），并且把每个像素点的色彩信息转为灰度值，这样就得到了一个 49 x 49 的矩阵。
然后，从左上角开始，依次取出一个小区块，进行计算。

![image](https://user-images.githubusercontent.com/101693157/158825889-204a8385-6e0e-49f3-89b7-dbe0e1ef269d.png)

上图是取出一个 5 x 5 的区块。下面的计算以 7 x 7 的区块为例。
接着，需要有一些现成的边缘模式，比如垂直、直角、圆、锐角等等。

![](https://www.ruanyifeng.com/blogimg/asset/2016/bg2016072205.png)

上图右边是一个圆角模式，左边是它对应的 7 x 7 灰度矩阵。可以看到，圆角所在的边缘灰度值比较高，其他地方都是0。
现在，就可以进行边缘识别了。下面是一张卡通老鼠的图片。
  
![](https://www.ruanyifeng.com/blogimg/asset/2016/bg2016072206.png)
取出左上角的区块。

![](https://www.ruanyifeng.com/blogimg/asset/2016/bg2016072209.png)
取样矩阵与模式矩阵对应位置的值相乘，进行累加，得到6600。这个值相当大，它说明什么呢？

![](https://www.ruanyifeng.com/blogimg/asset/2016/bg2016072207.png)

取样矩阵移到老鼠头部，与模式矩阵相乘，得到的值是0。

乘积越大就说明越匹配，可以断定区块里的图像形状是圆角。通常会预置几十种模式，每个区块计算出最匹配的模式，然后再对整张图进行判断。

### [图像与滤波](https://www.ruanyifeng.com/blog/2017/12/image-and-wave-filters.html)

前几天读到[一篇文章](https://medium.com/statuscode/filtering-images-using-web-audio-api-276555cca6ad)，它提到图像其实是一种波，可以用波的算法处理图像。我顿时有一种醍醐灌顶的感觉，从没想到这两个领域是相关的，图像还可以这样玩！下面我就来详细介绍这篇文章。

一、为什么图像是波？
  
我们知道，图像由像素组成。下图是一张 400 x 400 的图片，一共包含了 16 万个像素点。

![](https://www.ruanyifeng.com/blogimg/asset/2017/bg2017121301.jpg)

每个像素的颜色，可以用红、绿、蓝、透明度四个值描述，大小范围都是0 ～ 255，比如黑色是[0, 0, 0, 255]，白色是[255, 255, 255, 255]。通过 Canvas API 就可以拿到这些值。
如果把每一行所有像素（上例是400个）的红、绿、蓝的值，依次画成三条曲线，就得到了下面的图形。

![image](https://user-images.githubusercontent.com/101693157/158827129-1423d463-594b-4f22-aedc-d705f1d64ac9.png)

可以看到，每条曲线都在不停的上下波动。有些区域的波动比较小，有些区域突然出现了大幅波动（比如 54 和 324 这两点）。
对比一下图像就能发现，曲线波动较大的地方，也是图像出现突变的地方。

![](https://www.ruanyifeng.com/blogimg/asset/2017/bg2017121303.png)

这说明波动与图像是紧密关联的。图像本质上就是各种色彩波的叠加。
  
二、频率

综上所述，`图像就是色彩的波动：波动大，就是色彩急剧变化；波动小，就是色彩平滑过渡`。因此，波的各种指标可以用来描述图像。
频率（frequency）是波动快慢的指标，单位时间内波动次数越多，频率越高，反之越低。
上图是函数sin(Θ)的图形，在2π的周期内完成了一次波动，频率就是1。
上图是函数sin(2Θ)的图形，在2π的周期内完成了两次波动，频率就是2。
所以，色彩剧烈变化的地方，就是图像的高频区域；色彩稳定平滑的地方，就是低频区域。

三、滤波器
物理学对波的研究已经非常深入，提出了很多处理波的方法，其中就有滤波器（filter）：过滤掉某些波，保留另一些波。
下面是两种常见的滤波器 。
```
低通滤波器（lowpass）：减弱或阻隔高频信号，保留低频信号
高通滤波器（highpass）：减弱或阻隔低频信号，保留高频信号
```
下面是低通滤波的例子。

![image](https://user-images.githubusercontent.com/101693157/158827703-e450567f-fc23-406c-ba9d-4b3319f8bc40.png)

上图中，蓝线是原始的波形，绿线是低通滤波lowpass后的波形。可以看到，绿线的波动比蓝线小很多，非常平滑。
下面是高通滤波的例子。

![image](https://user-images.githubusercontent.com/101693157/158827747-239e4bf9-f935-4bd7-aad5-ac388d9f4bce.png)

上图中，黄线是原始的波形，蓝线是高通滤波highpass后的波形。可以看到，黄线的三个波峰和两个波谷（低频波动），在蓝线上都消失了，而黄线上那些密集的小幅波动（高频波动），则是全部被蓝线保留。
再看一个例子。

![image](https://user-images.githubusercontent.com/101693157/158827809-3ed3c246-5f83-4492-af08-744b2317f8ba.png)

上图有三根曲线，黄线是高频波动，红线是低频波动。它们可以合成为一根曲线，就是绿线。

![image](https://user-images.githubusercontent.com/101693157/158827832-b5b7426d-d6da-458f-8fe1-87cf7c82b2a3.png)

上图中，绿线进行低通滤波和高通滤波后，得到两根黑色的曲线，它们的波形跟原始的黄线和红线是完全一致的。

四、图像的滤波
浏览器实际上包含了滤波器的实现，因为 Web Audio API 里面定义了声波的滤波。这意味着可以通过浏览器，将lowpass和highpass运用于图像。
lowpass使得图像的高频区域变成低频，即色彩变化剧烈的区域变得平滑，也就是出现模糊效果。

![](https://www.ruanyifeng.com/blogimg/asset/2017/bg2017121310.jpg)
![image](https://user-images.githubusercontent.com/101693157/158828049-62b18a25-6b35-4716-9ef3-b2ed3681b563.png)

上图中，红线是原始的色彩曲线，蓝线是低通滤波后的曲线。
highpass正好相反，过滤了低频，只保留那些变化最快速最剧烈的区域，也就是图像里面的物体边缘，所以常用于边缘识别。

上图中，红线是原始的色彩曲线，蓝线是高通滤波后的曲线。

下面这个网址，可以将滤波器拖到图像上，产生过滤后的效果。

![image](https://user-images.githubusercontent.com/101693157/158828155-eede3bb4-6c9d-4855-b6c0-68113e565498.png)

浏览器实现滤波的范例代码，可以看这个[仓库](https://github.com/rssilva/web-audio-image-filtering)。

### [HTML5的视频格式之争](https://www.ruanyifeng.com/blog/2010/05/html5_codec_fight.html)

下一代的网页语言HTML5，提供了一个video标签。它允许开发者直接将视频嵌入网页，不需要任何第三方插件（比如 Adobe公司的Flash）就能播放。
这当然是一大进步。

但是，有一个核心问题，却没有得到解决。HTML5没有规定，浏览器到底应该播放哪一种格式的视频。浏览器厂商可以自行选择支持的格式。

现在，最流行的视频格式是H.264。它有很多优点，编码后生成的视频文件，体积较小，画质也不错。蓝光技术（Blu-ray）就采用这种格式，眼下几乎所有的高清摄像机----不管民用的还是商业的----都使用它。互联网上的在线视频播放，采用它的比例也正在不断上升。

不过，H.264是一种专利视频格式。它的专利被一家MPEG-LA公司控制。
这家公司专门负责管理与H.264有关的"专利池"（patent pool）。所谓"专利池"，就是指好几家公司把各自的H.264专利放在一起，组成一个"池"。其他人如果要使用H.264，就必须向"池"的管理公司申请许可，一旦获得了许可，就可以使用"池"中的所有专利。
这就是说，MPEG-LA公司是H.264的实际管理者和收费者。任何支持播放H.264视频的DVD播放机、蓝光播放机、摄像机或者别的设备，都必定有一张MPEG-LA颁发的许可证。

目前为了推广H.264，MPEG-LA规定，只要你的视频用于互联网上的免费播放，就可以无偿获得使用许可证。这就是为什么YouTube可以免费使用MPEG-LA许可证的原因。而像Netflix这样的付费收看公司，就得不到这种优惠了。
MPEG-LA的这种促销政策，并不会永远不变。当前的H.264免费许可证，将于2010年12月31日当期。那么，从2011年1月1日起，MPEG-LA会不会向YouTube、甚至向嵌入H.264视频的个人网站收费呢？完全存在这种可能。专利使用费会是多少？谁也不知道，这由MPEG-LA说了算。另一种可能是，MPEG-LA为了进一步推广H.264，继续保持免费政策，等到2、3年后，它一统市场了，再开始收费。到了那时，如果大多数公司都依赖这种格式，那么它们就别无选择，只能向MPEG-LA交钱。
一些人对这种情形，感到担忧和不满。他们决定自行开发一种没有专利的视频格式，生成的文件体积要与H.264相仿，画质也要差不多。这种格式就叫做Theora。

Theora的主要开发者，也是Ogg Vorbis（[译注] 一种开源的、无专利的音频压缩格式）的开发者。Theora的基础是On2 Technologies公司开发的VP3视频格式。本世纪初，On2公司将VP3放入了公共领域。Theora对VP3做了大量改进，并且在开发过程中非常小心，避免触犯到任何现存专利。结果，我们就有了一种任何人都可以免费使用、不用担心专利问题的视频格式。
听上去很欢欣鼓舞，对不对？但是为什么大家还在用H.264，还不是抛弃它呢？
  
这里有几个原因。
  
第一个原因。没有一家实体公司来承担Theora的专利责任，用户必须自己负责。万一将来有人起诉Theora侵犯了某某专利，用户很可能必须自己掏钱打官司。所以，业界有一种广泛的担心，现在之所以没人起诉Theora，并不是这些人不想起诉，而是要等到某一家大型公司开始采用Theora以后，有可能出现高额的专利赔偿金时，他们再来起诉。最近，苹果公司的CEO乔布斯，就公开表达了这种看法。
不过，话说回来，这么多年来，一直有人在威胁Theora，但是从来没人真的起诉。部分原因可能确实是Theora目前还没有重量级使用者，敲诈不到足够的金钱。不过，很多人相信还存在另一种原因，那就是这些"黑暗中的威胁者"害怕闹上法庭以后，万一法庭最后判决Theora胜诉，不存在任何专利问题，那么MPEG-LA公司的大麻烦就来了。因为大家可能就不会再付给它专利费了，而是放心地改为使用Theora了。

第二个原因。一些主要的大公司，本身就是MPEG-LA"专利池"的所有者，比如苹果公司和微软公司。它们各自拥有一些H.264专利，可以从推广H.264中赚到钱，Theora的普及将对它们的利润产生不利影响。所以，苹果公司的Safari浏览器和微软公司的IE浏览器，完全不支持Theora。

第三个原因。有一种观点认为，Theora生成的视频质量不如H.264。早期的Theora 1.0，确实效果不好；但是Theora 1.1 已经被证明，效果不逊于H.264，尤其是在低码率的情况下。对Theora的怀疑，导致基于Theora的硬件解码器非常少。这一点对Theora的打击很大。因为H.264解码芯片随处可见，苹果公司的每一台iTouch、iPhone、iPad里面都有，进一步说，过去5年中全世界生产的几乎每一台摄像机都支持H.264硬解码。

现在，再回过头谈HTML5和它的video标签。
开源浏览器Firefox和KHTML，没有资源去购买H.264许可证。因此，它们原生不支持H.264格式的视频，除非用户自己安装第三方插件。而微软公司和苹果公司则是完全不支持Theora，只支持H.264。
这意味着，未来的HTML5网页，不存在一种通用的视频格式。也就是说，HTML5网站开发者必须为同一个视频，准备两个格式的版本，一个是H.264，另一个是Theora。不过，开发者还有另一个选择，就是要求用户安装第三方插件。
猜猜看，大多数开发者会怎么做？他们很可能什么也不做！保持现状不就行了，让用户继续用Flash观看视频吧，什么麻烦都没了。
等一等！苹果公司已经宣布放弃Flash了。它的iPad、iPhone和iTouch，不支持任何形式的Flash。想在这些设备上播放视频的开发者，不得不求助于HTML5的video标签。
解决方案是什么？
我想大多数开发者会选择做一个浏览器"嗅探"，专门为苹果公司的设备提供一个H.264格式的视频，其余的设备则显示一个Flash播放器，里面也可以播放这个H.264格式的视频。所以，Flash和H.264成了赢家，Theora和开源软件成了输家，这真是一个令人悲哀的结果。
我们也许有机会避免这种结局。
去年，Google收购了On2 Technologies，并且计划把On2的VP8格式开源。 VP8和VP3是同一个体系的视频格式，这意味着它和Theora有亲缘关系。但是，VP8比VP3高出5个版本，这意味着它的效果应该好于Theora。那么，我们就会有一个更好的开源格式，它的背后是一家真正的大公司（Google）在支持。此外，全世界最大的视频网站Youtube，归Google所有，毫无疑问，它会采用VP8。因此，有了这些因素，我们就可能在今后几年中，看到VP8格式的视频飞速增长，把Theora和H.264都甩在身后。
不过，我的预测是，将来的互联网上，各种视频格式都有一席之地。Theora将继续得到开源浏览器（比如Firefox）的支持，苹果公司和微软公司将不断推进H.264，Google将尝试在YouTube上使用VP8。但是，Google也会被迫保留H.264和Flash格式的视频，这是为了支持苹果公司的设备和历史遗留下来的不支持HD视频的设备。
我很希望，Google把VP8放入公共领域。那样的话，Xiph就能利用VP8，做出Theora 2.0。然后，Firefox、 WebKit和Opera都开始支持Theora 2，YouTube也开始把它的视频转为VP8/Theora 2兼容格式，而Flash也将升级支持Theora 2。那么，只剩下苹果公司一家，它要么也支持Theora 2，要么只能开一个自己的视频分享网站，因为它的iPhone用户到时将无法收看Youtube。
这样的未来，难道不值得期待吗？

## 参考
1. [正态分布为什么常见？](https://www.ruanyifeng.com/blog/2017/08/normal-distribution.html)
2. [高斯模糊的算法](https://www.ruanyifeng.com/blog/2012/11/gaussian_blur.html)

![Alt](https://repobeats.axiom.co/api/embed/86211ab883763ed6c75fd14571647e7febb6919f.svg "Repobeats analytics image")

![Alt](https://repobeats.axiom.co/api/embed/cb158f7213b3e18079ae2f72ac4dec915ad48889.svg "Repobeats analytics image")
